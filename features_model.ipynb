{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_arrays():\n",
    "    df_1 = pd.read_csv(\"datasets/1_no_stopwords.csv\")\n",
    "    df_3 = pd.read_csv(\"datasets/3_no_stopwords.csv\")\n",
    "    df_5 = pd.read_csv(\"datasets/5_no_stopwords.csv\")\n",
    "    df_6 = pd.read_csv(\"datasets/6_no_stopwords.csv\")\n",
    "    \n",
    "    df = df_1.append(df_3)\n",
    "    df = df.append(df_5)\n",
    "    df = df.append(df_6)\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df[\"is_hatespeech\"])\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = load_data_arrays()\n",
    "\n",
    "\n",
    "# Convert the test- and train-DataFrames to Tensorflow Datasets\n",
    "\n",
    "train_labels = np.eye(2)[train_df['is_hatespeech'].values]\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(np.asarray(train_df['text'].values, dtype=str), tf.string),\n",
    "            tf.cast(train_labels, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "test_labels = np.eye(2)[test_df['is_hatespeech'].values]\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(np.asarray(test_df['text'].values, dtype=str), tf.string),\n",
    "            tf.cast(test_labels, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
      "array([b'which even matter this foo talk here 13112511515',\n",
      "       b'explanation toddst1 blocked completely clear community rejected onesided interaction ban completely ineffective1 2 3 4 5 behaviour completely one sided considering completely ignored similar behaviour gpms part here here even i brought attention talk page advised go ani 3 afterwards blocked following advice1 this massive abuse admin power content dispute favor proteges perfect example wpgame whats wrong wikipedia',\n",
      "       b'rt annie sunrise im wrong show could get worse mkr',\n",
      "       b'that certainly true however protests mainly highlight particular aspects carrolls addiction research tend draw sympathy if research stopped attention would probably diverted research using animal models particularly research monkeys would drop protests threshold notability iinans addiction research aspects experimentation seem quite unique important own possibly primate research ongoing umns neurosci cogsci departments',\n",
      "       b'fxdh if look swedish you fucking blind',\n",
      "       b'but ass diploma obscure street fighter trivia oh wait yes do youre wikipedia editor761075168',\n",
      "       b'fyi group via shut down mpegla seems pool',\n",
      "       b'thanks probably post wpani thats current discussion is talk',\n",
      "       b'hornet mafia article deletion nomination hell term even appears wikipedia discussion page an article created defining term subsequently nominated deletion purists identified himthemselves there if believe concept hornet mafia real ufo sighting believe wp article anything brittanica please participate wikipediaarticles deletionhornet mafia',\n",
      "       b'then remove it add blacklisted link place',\n",
      "       b'and fuck care 6716571214',\n",
      "       b'untagged images you uploaded 50 untagged images a list found here please correct them let know need help',\n",
      "       b'inactive how long someone appearcompete theyre considered inactive i think vito put inactive list',\n",
      "       b'links sites erroneous claims although antenna half wave end fed perform better half wave ground plane due lower angle radiation removed preserve technical literacy wikipedia',\n",
      "       b'cuchullian shaming word history extreme procatholic views hatred christians 122172118114',\n",
      "       b'on dec 9 tagishsimon listed imagedsc00003jpg ifd on dec 11 wrote somebody deleted this record deletion log deleted edits is bug please leave listing somebody figures happened did ever find happened if not may want move question somewhere else everything page normally deleted seven days \\xe2\\x80\\x93 talk 2015 dec 16 2004 utc',\n",
      "       b'im lazy i get homework time teachers i work around house stuff',\n",
      "       b'hahahaha manziel faggot browns ruin him win win',\n",
      "       b'i read law capital company thus hard determine owner such usually state companies explicitly state relevant law owns here checked 1950 1986 acts it wide range powers purchase borrow dispose course subject law oireachtas',\n",
      "       b'ive worked digital cash 20 years clear digital bearer token money ie chaumian blinded money could used represent arbitrary assets there difference distributed centralized systems right really viable distributed model blockchain based distinction cryptocurrency vs noncryptocurrency blockchainbased cryptocurrency vs blinded token cryptocurrency theyre distinct accountbased money there ways blinded money actually more cryptocurrency blockchain money eliminating historical record linkability inherent blockchain accountbased systems blinded tokens inherently fungible supports negotiability finality im sure solution article move enmasse blockchain currency merge bitcoin redirect cryptocurrency digital cash',\n",
      "       b'restoring honor any info mediation ok leave response here',\n",
      "       b'rebranstar thanks barnstar talk',\n",
      "       b'no thats exactly doing taking us another circle i think next step start adding material sources citing policy done make sure violations i well aware limits boundaries editor i hope others well it looks like bumpy ride take challenge npoving article',\n",
      "       b'please delete my user talk page and contributionshistory thanks\\nunblock',\n",
      "       b'i like attitude way think narrowminded mean person i new person wikipedia i still understand use copyright tags of course kennett kriner 50 yo pix i know that you know stuff i quit together you bullies wikipedians bloody jobs',\n",
      "       b'bitch you whiny ass attention whore bitch go choke cock',\n",
      "       b'bullshit turn garbage play radio today listen womans voice she outsang everyone as such ive reworded sentence little differently',\n",
      "       b'holi greetings hi i wishing happy holi unique indian celebration color brotherhood among members humanity the festival falls 15th march 2006 i collected a gift pack quotationsfor contained sections do things differently something more part ongoing discussion pertaining nomination adminship you aware tradition throw colored water flames burning holika enable prahlad emerge flames i convey holi greetings family',\n",
      "       b'fuck bitch i go house kill gun well prepare die',\n",
      "       b'1 are mitochondria found cells bacteria can provide documents references this all google results refer type bacteria recent discussion pertaining use knallgas bacteria genome sequence bioplasticproducing knallgas bacterium ralstonia eutropha digested cell envelope preparations obtained knallgas bacterium strain co2 fixation by knallgas bacteria\\n4 you opposed merge oxyhydrogen flame biological definition maybe separate article welding separate article name knallgas biological \\xe2\\x80\\x94',\n",
      "       b'oteti otu ocu want netu necu i dont want anyone know anything words i hear used montenegrins berane',\n",
      "       b'yes sophia summary bullet points side dispute describes arguments excellent idea enables noninvolved editors understand nature dipute hopefully bring unexplored perspectives resolution \\xe2\\x80\\xa2',\n",
      "       b'disputed section business career the article says born 1944 received mba 1968 original research simple math suggests 24 years old it would highly unusual 24 year old long term member board trustees major university did become board member 15 years old the citation dead link in wikipedia guess however guessing would received mba 1968 olin school business named board member later life',\n",
      "       b'ah haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahhahahah yaaa bitch yaaaa haahh',\n",
      "       b'djsasso correct if two separate franchises get two separate articles what trying akin arguing steve smith steve smith articles merged name played hockey lute',\n",
      "       b'let remind open ip edit related previous blocks\\nbtw course release ip renew new one anytime',\n",
      "       b'not computer will report bug search amp blocks later not sure intentional not seems suboptimal',\n",
      "       b'shes dumb bitch shouldve said no extra shit unnecessary lol relationship goals',\n",
      "       b'not mention as understandable possible common readers',\n",
      "       b'no i plan ask advice assume situations know sides know assume does makes ass me i found innocent several admins insist calling racist you\\xe2\\x80\\x99re prick i don\\xe2\\x80\\x99t plan talk all anyone jumps conclusions welcome speak myself your extremely biased i wont watching reply reading it your fucking idiot words spelled right',\n",
      "       b'hello abecedare i understand speedy deletion criteria ayyangar photo former lok sabha speaker it public domain clickedmore 60 years could please elaborate speedy deletion criteria we need evidence photograph taken 1949before claim image public domain india do indication',\n",
      "       b'for wrote me twat highest order david bret furthermore ever meet face face i punch fucking lights out',\n",
      "       b'iont got type bad bitches thing i like ayeee throw ass sphere',\n",
      "       b'i object revert it context convention torture clutter quotation violate principle leaving quotations unchanged mislead confuse reader to contrary keeps quotation intact yet still clarifies convention torture alluded to offers interested reader chance effortlessly jump full explanation desired',\n",
      "       b'hey dick as toho co ltd shareholder block even tried go ahead delete again i hope understand well i recommend keep anonymous user wikipedia recognized academia me and quite frankly life nonprofit nonsense hogs google search dismissed now get life go block again loser',\n",
      "       b'curtisnaitos article edits disruptive last months campaigning get banned wikipedia criticizing edits he managed sneak several poorlysourced articles past ga process articles reassessed accordance ga criteria all users commented issue agree me my offering request reassessments curtisnaito stops following harassing peace offering threat \\xe8\\x81\\x96\\xe3\\x82\\x84\\xe3\\x82\\x84',\n",
      "       b'hi kedadi page i see support highly controversal reunification albania idea also known irridentistic often extremist great albania ideology i right here another related article nla acts described terrorism thank you',\n",
      "       b'i appreciate you like good little tool passed along hacksaw equation way tow jackass party line heil jimbo i also appreciate fact gwernol combined stupid see part cincinnati enquirer mount website talks nursing popular mount academic program added teachers criminology program and behavioral science programs general other way work hard wiki',\n",
      "       b'eid mubarak\\nallahuakbar allah greatest these first words muslim child hears entering world the father makes call prayer ears welcometothisworld message the call heard wherever muslims five times day the prayers also begin pronouncement certainly emblem islamic faith there power world equal power one god allah greatest may allah bless every 1 of us\\nameen \\xd8\\xb9\\xdb\\x8c\\xd8\\xaf \\xd9\\x85\\xd8\\xa8\\xd8\\xa7\\xd8\\xb1\\xda\\xa9',\n",
      "       b'ive started 2nd report',\n",
      "       b'stick the facts people contributing internet encyclopedia stick facts ryan case accusations allegations hearsay unsigned alleged verbals unsigned alleged confessions hypotheticals personal opinions personal views included as time passes people directly involved ryan case die bitter people believe right corrupt facts attempt distort truth suit stealth agendas the facts scientific ballistic forensic evidence prove ryan guilty beyond reasonable doubt the facts ryan convicted murder executed despite total lack forensic examinations missing pieces vital evidence might cleared ryan dire inconsistencies fourteen eyewitnesses evidence alleged unsigned verbalsconfessions said made ryan police they facts',\n",
      "       b'p fucking s miranda coolie thanks cooperation betraying megalomaniacal thai hooker attitude owns world every wog it what cunt',\n",
      "       b'incorrect this page technically correct according playercompiled tau lexicon which sites gw publication tau a z gws guela auxiliary army guela term applied humans allied tau im going mark page stub now changes made week return take stab making comprehensive article',\n",
      "       b'7seriesbot we got thanks talk\\xe2\\x86\\x92 \\xe2\\x86\\x90track',\n",
      "       b'what net worth in article says 88 million but caption says 52 m',\n",
      "       b'why people continue remove sourced material wiki site',\n",
      "       b'more second amendment articel likely kenosis saltyboatr person using different ids the discussion talk page still heated i noticed salty boatr responding message left kenosis there bunch additions two likely peson noticed mistake wanted cover up showing message left kenosis what source who wrote it it looks like hodgepodge blurbs antifederalists pa pulled somewhere id interested know stuff culled as article text wrt pennsylvania minority presently reads follows another nonmilitary usage phrase found oneman pennsylvania minority report published ratifying convention cited uviller merkel turn cite rss selected quotation minority report at least discrepancy sorted out i would advocate changing text passage something like another nonmilitary usage phrase found pennsylvania antifederalist minority report published states constitutional convention followed selected quotation minority report just cautious here id recommend citation uviller merkel another wprs representative position minority consisted of it twentysomething participantssigners whether fact part convention not kenosis talk arent capable clicking link looking i deleting uviller merker material article unprotected engage historical revisionism forbidden wiki policies slander also forbidden wikipedia policies96237123191 talk and salty boatr responding without intervbening posts intended confuse i capable looking i looked you using primary sources allowed per policy wpnor we must use reliable third party published sources saltyboatr talk hope helps96237123191',\n",
      "       b'insane\\nmos def notable necro\\nmos def gay rapper rhymes soft insults white people goes white women\\nall writing hiphop excludes necro everything\\nu talk underground hiphop dont mention him\\nu talk eastcoast hiphop dont mention necro\\nu r lost sauce\\nall speaking black experience ignoring white experience\\nu r racist come\\nand fan thinks necro best represented\\ni dont like articles\\nand feel false remove',\n",
      "       b'svetovid i think reasonable include statements seem ambiguous subjective surrounding text clear this persongroup believes this substantiated empirical fact destiny karma important concept anthroposophy waldorf education whether reality karma objectively substantiated subject article',\n",
      "       b'stop oppressing me have heard free speech stop shoving lifestyle throat 1st amendment tcot teabaggers',\n",
      "       b'removed part i removed new subsection correct irrelevent might go somewhere else 0000 30 mar 2004 utc',\n",
      "       b'a message you shadeed\\nhi ngger',\n",
      "       b'pov change removed sentence military secrecy referenced doublespeak i felt sounded accusatory paranoid\\n76213517',\n",
      "       b'i reviewed article placed hold there one reference left fixed whole thing passes its reference that according checklinks expire once fixed i pass article \\xe2\\x80\\xa2 talk \\xe2\\x80\\xa2'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
      "array([[1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [0, 1],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "# print(train_dataset)\n",
    "print(next(iter(train_dataset)))\n",
    "# print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kw = pd.read_csv(\"datasets/bad_words.csv\")\n",
    "kw_vocab = set()\n",
    "for idx, item in df_kw.iterrows():\n",
    "  kw_vocab.add(item[0])\n",
    "kw_vocab_len = len(kw_vocab) + 1\n",
    "kw_layer = tf.keras.layers.TextVectorization(vocabulary=list(kw_vocab))\n",
    "kw_layer.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "ec_layer = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "ec_layer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(kw_layer([\"You are a nice little idiot\"]))\n",
    "# print(ec_layer([\"You are a nice little idiot\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2717/2717 [==============================] - 510s 179ms/step - loss: 0.4050 - accuracy: 0.8795 - val_loss: 0.3609 - val_accuracy: 0.8953\n",
      "Epoch 2/5\n",
      "2717/2717 [==============================] - 1044s 384ms/step - loss: 0.3077 - accuracy: 0.9148 - val_loss: 0.3065 - val_accuracy: 0.8984\n",
      "Epoch 3/5\n",
      "2717/2717 [==============================] - 935s 344ms/step - loss: 0.2554 - accuracy: 0.9237 - val_loss: 0.2728 - val_accuracy: 0.9078\n",
      "Epoch 4/5\n",
      "2717/2717 [==============================] - 1041s 383ms/step - loss: 0.2251 - accuracy: 0.9312 - val_loss: 0.2542 - val_accuracy: 0.9125\n",
      "Epoch 5/5\n",
      "2717/2717 [==============================] - 822s 303ms/step - loss: 0.2089 - accuracy: 0.9333 - val_loss: 0.2447 - val_accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "input_layer = layers.Input(shape=(1,), dtype=(tf.string))\n",
    "seq_layer = kw_layer(input_layer)\n",
    "seq_layer = layers.Embedding(input_dim=len(kw_layer.get_vocabulary()), output_dim=64, mask_zero=True)(seq_layer)\n",
    "seq_layer = layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(seq_layer)\n",
    "seq_layer = layers.Bidirectional(tf.keras.layers.LSTM(32))(seq_layer)\n",
    "seq_layer = layers.Dense(64, activation='relu')(seq_layer)\n",
    "seq_layer = layers.Dropout(0.5)(seq_layer)\n",
    "seq_layer = layers.Dense(2, activation='softmax')(seq_layer)\n",
    "seq2_layer = ec_layer(input_layer)\n",
    "seq2_layer = layers.Embedding(input_dim=len(ec_layer.get_vocabulary()), output_dim=64, mask_zero=True)(seq2_layer)\n",
    "seq2_layer = layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(seq2_layer)\n",
    "seq2_layer = layers.Bidirectional(tf.keras.layers.LSTM(32))(seq2_layer)\n",
    "seq2_layer = layers.Dense(64, activation='relu')(seq2_layer)\n",
    "seq2_layer = layers.Dropout(0.5)(seq2_layer)\n",
    "seq2_layer = layers.Dense(2, activation='softmax')(seq2_layer)\n",
    "concat_layer = layers.Concatenate(axis=1)([seq_layer, seq2_layer])\n",
    "output_layer = layers.Dense(2, activation='softmax')(concat_layer)\n",
    "\n",
    "model = tf.keras.Model(name=\"hatespeech_detector\", inputs=input_layer, outputs=output_layer)\n",
    "# print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_dataset, epochs=5, validation_data=test_dataset, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hatespeech_detector\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, None)        0           ['input_2[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " text_vectorization_1 (TextVect  (None, None)        0           ['input_2[0][0]']                \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 64)     183552      ['text_vectorization[1][0]']     \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 64)     64000       ['text_vectorization_1[1][0]']   \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, None, 128)   66048       ['embedding_2[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirectional  (None, None, 128)   66048       ['embedding_3[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 64)          41216       ['bidirectional_4[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 64)          41216       ['bidirectional_6[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           4160        ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            130         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 2)            130         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4)            0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 2)            10          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 470,670\n",
      "Trainable params: 470,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 100s 146ms/step - loss: 0.2095 - accuracy: 0.9323\n",
      "Test Loss: 0.2095242589712143\n",
      "Test Accuracy: 0.9322841167449951\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00668358 0.9933164 ]\n",
      " [0.9894041  0.01059597]]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "sample_text = ['You are such a stupid fucking whore',\n",
    "               'I would not recommend this movie.']\n",
    "predictions = model.predict(np.array(sample_text))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ein Unterverzeichnis oder eine Datei mit dem Namen \"models\" existiert bereits.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/binary_features\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/binary_features\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D85866EA60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D8586707C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D85DF2DFA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D85DF402B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D8598D9760> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D85AAD9520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D860199D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D8615B0040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "!mkdir models\n",
    "model.save('models/binary_features')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9a9cabc42f5adcc0f3294cfdbbe9ffcb3a15664c9675865bec9473cb4197e8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('.venv2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
